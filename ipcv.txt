import cv2

vid = cv2.VideoCapture('juggling.mp4')

frameWidth, frameHeight = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)), int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))
out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), 30, (350, frameHeight))

while True:
    ret, frame = vid.read()
    if ret:
        resize = cv2.resize(frame, (1000, frameHeight))
        cropped = resize[0:frameHeight, 350:700]
        out.write(cropped)

        cv2.imshow('Video', cropped)

        if cv2.waitKey(30) & 0xFF == ord('q'):
            break
    else:
        break
w, h = int(out.get(cv2.CAP_PROP_FRAME_WIDTH)), int(out.get(cv2.CAP_PROP_FRAME_HEIGHT))
print(w)
print(h)
out.release()
vid.release()
cv2.destroyAllWindows()


from collections import deque
from imutils.video import VideoStream
import numpy as np
import argparse
import cv2
import imutils
import time

vid = cv2.VideoCapture('output.mp4')

greenLower = (50, 86, 6)
greenUpper = (64, 255, 255)
pinkUpper = (172, 246, 255)
pinkLower = (157, 106, 157)
blueUpper = (95, 255, 178)
blueLower = (88, 171, 128)

GreenPts = deque(maxlen=32)
PinkPts = deque(maxlen=32)
BluePts = deque(maxlen=32)

(GdX, GdY) = (0, 0)
(PdX, PdY) = (0, 0)
(BdX, BdY) = (0, 0)

GreenDirection = ""
PinkDirection = ""
BlueDirection = ""

# allow the camera or video file to warm up
time.sleep(2.0)

# keep looping
while True:
    frame = vid.read()
    frame = frame[1] if vid else frame

    if frame is None:
        break

    blurred = cv2.GaussianBlur(frame, (11, 11), 0)
    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

    GreenMask = cv2.inRange(hsv, greenLower, greenUpper)
    GreenMask = cv2.erode(GreenMask, None, iterations=2)
    GreenMask = cv2.dilate(GreenMask, None, iterations=2)

    PinkMask = cv2.inRange(hsv, pinkLower, pinkUpper)
    PinkMask = cv2.erode(PinkMask, None, iterations=2)
    PinkMask = cv2.dilate(PinkMask, None, iterations=2)

    BlueMask = cv2.inRange(hsv, blueLower, blueUpper)
    BlueMask = cv2.erode(BlueMask, None, iterations=2)
    BlueMask = cv2.dilate(BlueMask, None, iterations=2)

    GreenContour = cv2.findContours(GreenMask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    GreenContour = imutils.grab_contours(GreenContour)

    PinkContour = cv2.findContours(PinkMask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    PinkContour = imutils.grab_contours(PinkContour)

    BlueContour = cv2.findContours(BlueMask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    BlueContour = imutils.grab_contours(BlueContour)

    # only proceed if at least one contour was found
    if len(GreenContour) > 0:
        center = None
        # find the largest contour in the mask, then use
        # it to compute the minimum enclosing circle and
        # centroid
        c = max(GreenContour, key=cv2.contourArea)
        ((x, y), radius) = cv2.minEnclosingCircle(c)
        M = cv2.moments(c)
        center = (int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"]))
        # only proceed if the radius meets a minimum size
        if radius > 10:
            # draw the circle and centroid on the frame,
            # then update the list of tracked points
            cv2.circle(frame, (int(x), int(y)), int(radius),
                       (0, 255, 255), 2)
            cv2.circle(frame, center, 5, (0, 0, 255), -1)
            GreenPts.appendleft(center)

    for i in np.arange(1, len(GreenPts)):
        if GreenPts[i - 1] is None or GreenPts[i] is None:
            continue

    cv2.putText(frame, GreenDirection, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 255, 0), 3)
    cv2.putText(frame, "Green dx:{}, Green dy:{}".format(x, y), (10, frame.shape[0] - 40), cv2.FONT_HERSHEY_SIMPLEX,
                0.35,
                (0, 255, 0), 1)

    if len(PinkContour) > 0:
        center = None
        # find the largest contour in the mask, then use
        # it to compute the minimum enclosing circle and
        # centroid
        c = max(PinkContour, key=cv2.contourArea)
        ((x, y), radius) = cv2.minEnclosingCircle(c)
        M = cv2.moments(c)
        center = (int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"]))
        # only proceed if the radius meets a minimum size
        if radius > 10:
            # draw the circle and centroid on the frame,
            # then update the list of tracked points
            cv2.circle(frame, (int(x), int(y)), int(radius),
                       (0, 255, 255), 2)
            cv2.circle(frame, center, 5, (0, 0, 255), -1)
            PinkPts.appendleft(center)

    for i in np.arange(1, len(PinkPts)):
        if PinkPts[i - 1] is None or PinkPts[i] is None:
            continue

    cv2.putText(frame, PinkDirection, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 255, 0), 3)
    cv2.putText(frame, "Pink dx:{}, Pink dy:{}".format(x, y), (10, frame.shape[0] - 50), cv2.FONT_HERSHEY_SIMPLEX,
                0.35,
                (255, 0, 212), 1)

    if len(BlueContour) > 0:
        center = None
        # find the largest contour in the mask, then use
        # it to compute the minimum enclosing circle and
        # centroid
        c = max(BlueContour, key=cv2.contourArea)
        ((x, y), radius) = cv2.minEnclosingCircle(c)
        M = cv2.moments(c)
        center = (int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"]))
        # only proceed if the radius meets a minimum size
        if radius > 10:
            # draw the circle and centroid on the frame,
            # then update the list of tracked points
            cv2.circle(frame, (int(x), int(y)), int(radius),
                       (0, 255, 255), 2)
            cv2.circle(frame, center, 5, (0, 0, 255), -1)
            BluePts.appendleft(center)

    for i in np.arange(1, len(BluePts)):
        if BluePts[i - 1] is None or BluePts[i] is None:
            continue

    cv2.putText(frame, BlueDirection, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 255, 0), 3)
    cv2.putText(frame, "Blue dx:{}, Blue dy:{}".format(x, y), (10, frame.shape[0] - 60), cv2.FONT_HERSHEY_SIMPLEX,
                0.35,
                (240, 100, 100), 1)

    cv2.imshow("Frame", frame)
    if cv2.waitKey(30) & 0xFF == ord('q'):
        break
vid.release()
# close all windows
cv2.destroyAllWindows()


import cv2

net = cv2.dnn.readNetFromTensorflow("graph_opt.pb")
cap = cv2.VideoCapture('output.mp4')
cap.set(3, 800)
cap.set(4, 800)
inWidth = 368
inHeight = 368
thr = 0.1
frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

outputVideo = cv2.VideoWriter('outputPose1.mp4', cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), 30, (350, frameHeight))

BODY_PARTS = { "Nose": 0, "Neck": 1, "RShoulder": 2, "RElbow": 3, "RWrist": 4,
               "LShoulder": 5, "LElbow": 6, "LWrist": 7, "RHip": 8, "RKnee": 9,
               "RAnkle": 10, "LHip": 11, "LKnee": 12, "LAnkle": 13, "REye": 14,
               "LEye": 15, "REar": 16, "LEar": 17, "Background": 18 }

POSE_PAIRS = [ ["Neck", "RShoulder"], ["Neck", "LShoulder"], ["RShoulder", "RElbow"],
               ["RElbow", "RWrist"], ["LShoulder", "LElbow"], ["LElbow", "LWrist"],
               ["Neck", "RHip"], ["RHip", "RKnee"], ["RKnee", "RAnkle"], ["Neck", "LHip"],
               ["LHip", "LKnee"], ["LKnee", "LAnkle"], ["Neck", "Nose"], ["Nose", "REye"],
               ["REye", "REar"], ["Nose", "LEye"], ["LEye", "LEar"] ]

if not cap.isOpened():
    cap = cv2.VideoCapture(0)
if not cap.isOpened():
    raise IOError("Cannot be opened")

while cv2.waitKey(1) < 0:
    hasFrame, frame = cap.read()
    if not hasFrame:
        cv2.waitKey()
        break

    frameWidth = frame.shape[1]
    frameHeight = frame.shape[0]
    net.setInput(cv2.dnn.blobFromImage(frame, 1.0, (inWidth, inHeight), (127.5, 127.5, 127.5), swapRB=True, crop=False))
    out = net.forward()
    out = out[:, :19, :, :]

    assert(len(BODY_PARTS) == out.shape[1])

    points = []

    for i in range(len(BODY_PARTS)):
        heatMap = out[0, i, :, :]
        _, conf, _, point = cv2.minMaxLoc(heatMap)
        x = (frameWidth * point[0]) / out.shape[3]
        y = (frameHeight * point[1]) / out.shape[2]
        points.append((int(x), int(y)) if conf > thr else None)

    for pair in POSE_PAIRS:
        partFrom = pair[0]
        partTo = pair[1]
        assert(partFrom in BODY_PARTS)
        assert(partTo in BODY_PARTS)

        idFrom = BODY_PARTS[partFrom]
        idTo = BODY_PARTS[partTo]

        if points[idFrom] and points[idTo]:
            cv2.line(frame, points[idFrom], points[idTo], (0, 255, 0), 3)
            cv2.ellipse(frame, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv2.FILLED)
            cv2.ellipse(frame, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv2.FILLED)

    outputVideo.write(frame)
    cv2.imshow('Pose Estimation', frame)

    if cv2.waitKey(30) & 0xFF == ord('q'):
        break
cap.release()
# close all windows
cv2.destroyAllWindows()





from collections import deque
from imutils.video import VideoStream
import numpy as np
import argparse
import cv2
import imutils
import time

vid = cv2.VideoCapture('juggling.mp4')

greenLower = (50, 86, 6)
greenUpper = (64, 255, 255)
pinkUpper = (172, 246, 255)
pinkLower = (157, 106, 157)
blueUpper = (95, 255, 178)
blueLower = (88, 171, 128)

GreenPts = deque(maxlen=32)
PinkPts = deque(maxlen=32)
BluePts = deque(maxlen=32)

(GdX, GdY) = (0, 0)
(PdX, PdY) = (0, 0)
(BdX, BdY) = (0, 0)

GreenDirection = ""
PinkDirection = ""
BlueDirection = ""

net = cv2.dnn.readNetFromTensorflow("graph_opt.pb")
inWidth = 368
inHeight = 368
thr = 0.1
# allow the camera or video file to warm up
time.sleep(2.0)

BODY_PARTS = {"Nose": 0, "Neck": 1, "RShoulder": 2, "RElbow": 3, "RWrist": 4,
              "LShoulder": 5, "LElbow": 6, "LWrist": 7, "RHip": 8, "RKnee": 9,
              "RAnkle": 10, "LHip": 11, "LKnee": 12, "LAnkle": 13, "REye": 14,
              "LEye": 15, "REar": 16, "LEar": 17, "Background": 18}

POSE_PAIRS = [["Neck", "RShoulder"], ["Neck", "LShoulder"], ["RShoulder", "RElbow"],
              ["RElbow", "RWrist"], ["LShoulder", "LElbow"], ["LElbow", "LWrist"],
              ["Neck", "RHip"], ["RHip", "RKnee"], ["RKnee", "RAnkle"], ["Neck", "LHip"],
              ["LHip", "LKnee"], ["LKnee", "LAnkle"], ["Neck", "Nose"], ["Nose", "REye"],
              ["REye", "REar"], ["Nose", "LEye"], ["LEye", "LEar"]]

frameWidth, frameHeight = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)), int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))
out = cv2.VideoWriter('output1.mp4', cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), 30, (350, frameHeight))

while True:
    ret, frame = vid.read()
    if ret:
        resize = cv2.resize(frame, (1000, frameHeight))
        cropped = resize[0:frameHeight, 350:700]

        blurred = cv2.GaussianBlur(cropped, (11, 11), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        GreenMask = cv2.inRange(hsv, greenLower, greenUpper)
        GreenMask = cv2.erode(GreenMask, None, iterations=2)
        GreenMask = cv2.dilate(GreenMask, None, iterations=2)

        PinkMask = cv2.inRange(hsv, pinkLower, pinkUpper)
        PinkMask = cv2.erode(PinkMask, None, iterations=2)
        PinkMask = cv2.dilate(PinkMask, None, iterations=2)

        BlueMask = cv2.inRange(hsv, blueLower, blueUpper)
        BlueMask = cv2.erode(BlueMask, None, iterations=2)
        BlueMask = cv2.dilate(BlueMask, None, iterations=2)

        GreenContour = cv2.findContours(GreenMask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        GreenContour = imutils.grab_contours(GreenContour)

        PinkContour = cv2.findContours(PinkMask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        PinkContour = imutils.grab_contours(PinkContour)

        BlueContour = cv2.findContours(BlueMask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        BlueContour = imutils.grab_contours(BlueContour)

        if len(GreenContour) > 0:
            center = None
            # find the largest contour in the mask, then use
            # it to compute the minimum enclosing circle and
            # centroid
            c = max(GreenContour, key=cv2.contourArea)
            ((x, y), radius) = cv2.minEnclosingCircle(c)
            M = cv2.moments(c)
            center = (int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"]))
            # only proceed if the radius meets a minimum size
            if radius > 10:
                # draw the circle and centroid on the frame,
                # then update the list of tracked points
                cv2.circle(cropped, (int(x), int(y)), int(radius),
                           (0, 255, 255), 2)
                cv2.circle(cropped, center, 5, (0, 0, 255), -1)
                GreenPts.appendleft(center)

        for i in np.arange(1, len(GreenPts)):
            if GreenPts[i - 1] is None or GreenPts[i] is None:
                continue

            if i == 10 and GreenPts[i - 10] is not None:
                GreenX = GreenPts[i - 10][0] - GreenPts[i][0]
                GreenY = GreenPts[i - 10][1] - GreenPts[i][1]
                (directionX, directionY) = ("", "")
                if np.abs(GreenX) > 20:
                    directionX = "Right" if np.sign(GreenX) == 1 else "Left"
                if np.abs(GreenY) > 20:
                    directionY = "Down" if np.sign(GreenY) == 1 else "Up"
                if directionX != "" and directionY != "":
                    GreenDirection = "{}-{}".format(directionX, directionY)
                else:
                    GreenDirection = directionX if directionX != "" else directionY

        cv2.putText(cropped, GreenDirection, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 255, 0), 2)
        cv2.putText(cropped, "Green dx:{}, Green dy:{}".format(x, y), (10, cropped.shape[0] - 40),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.35,
                    (0, 255, 0), 1)

        if len(PinkContour) > 0:
            center = None
            # find the largest contour in the mask, then use
            # it to compute the minimum enclosing circle and
            # centroid
            c = max(PinkContour, key=cv2.contourArea)
            ((x, y), radius) = cv2.minEnclosingCircle(c)
            M = cv2.moments(c)
            center = (int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"]))
            # only proceed if the radius meets a minimum size
            if radius > 10:
                # draw the circle and centroid on the frame,
                # then update the list of tracked points
                cv2.circle(cropped, (int(x), int(y)), int(radius),
                           (0, 255, 255), 2)
                cv2.circle(cropped, center, 5, (0, 0, 255), -1)
                PinkPts.appendleft(center)

        for i in np.arange(1, len(PinkPts)):
            if PinkPts[i - 1] is None or PinkPts[i] is None:
                continue

            if i == 10 and PinkPts[i - 10] is not None:
                PinkX = PinkPts[i - 10][0] - PinkPts[i][0]
                PinkY = PinkPts[i - 10][1] - PinkPts[i][1]
                (directionX, directionY) = ("", "")
                if np.abs(PinkX) > 20:
                    directionX = "Right" if np.sign(PinkX) == 1 else "Left"
                if np.abs(PinkY) > 20:
                    directionY = "Down" if np.sign(PinkY) == 1 else "Up"
                if directionX != "" and directionY != "":
                    PinkDirection = "{}-{}".format(directionX, directionY)
                else:
                    PinkDirection = directionX if directionX != "" else directionY

        cv2.putText(cropped, PinkDirection, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (255, 0, 212), 2)
        cv2.putText(cropped, "Pink dx:{}, Pink dy:{}".format(x, y), (10, cropped.shape[0] - 50),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.35,
                    (255, 0, 212), 1)

        if len(BlueContour) > 0:
            center = None
            # find the largest contour in the mask, then use
            # it to compute the minimum enclosing circle and
            # centroid
            c = max(BlueContour, key=cv2.contourArea)
            ((x, y), radius) = cv2.minEnclosingCircle(c)
            M = cv2.moments(c)
            center = (int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"]))
            # only proceed if the radius meets a minimum size
            if radius > 10:
                # draw the circle and centroid on the frame,
                # then update the list of tracked points
                cv2.circle(cropped, (int(x), int(y)), int(radius),
                           (0, 255, 255), 2)
                cv2.circle(cropped, center, 5, (0, 0, 255), -1)
                BluePts.appendleft(center)

        for i in np.arange(1, len(BluePts)):
            if BluePts[i - 1] is None or BluePts[i] is None:
                continue

            if i == 10 and BluePts[i - 10] is not None:
                BlueX = BluePts[i - 10][0] - BluePts[i][0]
                BlueY = BluePts[i - 10][1] - BluePts[i][1]
                (directionX, directionY) = ("", "")
                if np.abs(BlueX) > 20:
                    directionX = "Right" if np.sign(BlueX) == 1 else "Left"
                if np.abs(BlueY) > 20:
                    directionY = "Down" if np.sign(BlueY) == 1 else "Up"
                if directionX != "" and directionY != "":
                    BlueDirection = "{}-{}".format(directionX, directionY)
                else:
                    BlueDirection = directionX if directionX != "" else directionY

        cv2.putText(cropped, BlueDirection, (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (240, 100, 100), 2)
        cv2.putText(cropped, "Blue dx:{}, Blue dy:{}".format(x, y), (10, cropped.shape[0] - 60),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.35,
                    (240, 100, 100), 1)

        frameWidth1 = cropped.shape[1]
        frameHeight1 = cropped.shape[0]

        net.setInput(
            cv2.dnn.blobFromImage(cropped, 1.0, (inWidth, inHeight), (127.5, 127.5, 127.5), swapRB=True, crop=False))
        output = net.forward()
        output = output[:, :19, :, :]

        assert (len(BODY_PARTS) == output.shape[1])

        points = []

        for i in range(len(BODY_PARTS)):
            heatMap = output[0, i, :, :]
            _, conf, _, point = cv2.minMaxLoc(heatMap)
            x = (frameWidth1 * point[0]) / output.shape[3]
            y = (frameHeight1 * point[1]) / output.shape[2]
            points.append((int(x), int(y)) if conf > thr else None)

        for pair in POSE_PAIRS:
            partFrom = pair[0]
            partTo = pair[1]
            assert (partFrom in BODY_PARTS)
            assert (partTo in BODY_PARTS)

            idFrom = BODY_PARTS[partFrom]
            idTo = BODY_PARTS[partTo]

            if points[idFrom] and points[idTo]:
                cv2.line(cropped, points[idFrom], points[idTo], (0, 255, 0), 3)
                cv2.ellipse(cropped, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv2.FILLED)
                cv2.ellipse(cropped, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv2.FILLED)

        cv2.imshow("Frame", cropped)
        out.write(cropped)
        if cv2.waitKey(30) & 0xFF == ord('q'):
            break
    else:
        break

w, h = int(out.get(cv2.CAP_PROP_FRAME_WIDTH)), int(out.get(cv2.CAP_PROP_FRAME_HEIGHT))
print("Output frame Height:", frameHeight1)
print("Output frame Width:", frameWidth1)
out.release()
vid.release()
cv2.destroyAllWindows()
